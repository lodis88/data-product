model <- train(x, y, method="nb", trControl = trainControl(method="cv", number=10))
x <- traindata[,-160]
model <- train(x, y, method="nb", trControl = trainControl(method="cv", number=10))
y <- as.factor(traindata$classe)
model <- train(x, y, method="nb", trControl = trainControl(method="cv", number=10))
getModelInfo("nb")
model <- train(classe ~., data=traindata, method="nb")
rm(x, y)
traindata$classe <- factor(traindata$classe)
model <- train(classe ~., data=traindata, method="nb")
class(traindata$classe)
data2 <- read.csv("pml-training.csv")
data2$classe
class(data2$classe)
str(data2)
model <- train(classe ~., data=data2, method="nb")
warnings()
require(ggplot2)
require(caret)
data <- read.csv("pml-training.csv")
class.histogram <- ggplot(data, aes(x=classe, fill = classe)) +
geom_histogram()+
labs(title = "Figure A: histogram of classe variable", x = "the class", y = "total nr of instances for that class")
class.histogram
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
traindata <- data[inTrain,]
validation <- data[-inTrain,]
set.seed(123)
?preProcess
?train
set.seed(123)
tc <- trainControl(method="cv", number = 5)
model <- train(classe ~., data=traindata, method="nb", preProcess = "pca", trControl = tc)
pp <- prcomp(traindata, center = TRUE, scale = FALSE)
str(traindata)
require(ggplot2)
require(caret)
data <- read.csv("pml-training.csv", stringsAsFactors=FALSE)
data$classe <- as.factor(data$classe)
class.histogram <- ggplot(data, aes(x=classe, fill = classe)) +
geom_histogram()+
labs(title = "Figure A: histogram of classe variable", x = "the class", y = "total nr of instances for that class")
class.histogram
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
traindata <- data[inTrain,]
validation <- data[-inTrain,]
set.seed(123)
tc <- trainControl(method="cv", number = 5)
pp <- prcomp(traindata, center = TRUE, scale = FALSE)
str(traindata)
df <- data.frame(lapply(data, 2, class))
?lapply
df <- data.frame(lapply(data, class))
str(df)
rm(df, tc,)
tc <- trainControl(method="cv", number = 5)
model <- train(classe ~., data=traindata, method="nb", preProcess = "knnImpute", trControl = tc)
traindata$classe
class(traindata$classe)
data <- read.csv("pml-training.csv")
data$classe <- as.factor(data$classe)
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
traindata <- data[inTrain,]
validation <- data[-inTrain,]
set.seed(123)
tc <- trainControl(method="cv", number = 5)
model <- train(classe ~., data=traindata, method="nb", preProcess = "knnImpute", trControl = tc)
warnings()
model
rm(model)
pp <- preProcess(method = "knnImpute", k=2)
pp <- preProcess(traindata, method = "knnImpute", k=2)
model <- train(classe ~., data=traindata, method="rf", mtry=16, trControl = tc)
model <- train(classe ~., data=traindata, method="rf", trControl = tc)
model
model$Accuracy
model$method
model$results$Accuracy
confusionMatrix(validation$classe, predict(model, validation))
preds <- predict(model, validation)
length(preds)
preds <- predict(model$finalModel, validation)
?predict
preds <- predict(model$finalModel, na.action="na.ignore", validation)
?na.action
rm(preds)
?randomForest
preds <- predict(model$finalModel, newdata = validation)
nrow(complete.cases(data))
sum(complete.cases(data))
test <- complete.cases(data)
testtrain <- traindata[complete.cases(data),]
testtrain <- traindata[complete.cases(traindata),]
testvalidate <- validation[complete.cases(validation),]
model2 <- train(classe ~., data=testtrain, method="rf", trControl = tc)
model2
preds <- predict(model2$finalModel, testvalidate)
require("missForest")
install.packages(missForest)
install.packages("missForest")
library(missForest)
rm(testtrain, testvalidate, model2, test)
?missForest
result <- missForest(validation)
data <- read.csv("pml-training.csv", stringsAsFactors=FALSE, na.strings=c("", "NA", "NULL"))
data$classe <- as.factor(data$classe)
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
traindata <- data[inTrain,]
validation <- data[-inTrain,]
set.seed(123)
tc <- trainControl(method="cv", number = 5)
result <- missForest(validation)
rm(model, tc)
traindata <- traindata[complete.cases(traindata),]
validation <- validation[complete.cases(validation),]
?randomForest
model <- randomForest(x=traindata[,-160], y=traindata$classe, xtest=validation[,-160], ytest=validation$classe, ntree=600)
model <- randomForest(na.action=na.ignore, x=traindata[,-160], y=traindata$classe, xtest=validation[,-160], ytest=validation$classe, ntree=600)
str(traindata)
traindata[traindata==#DIV/0!] <- NA
traindata[traindata==0] <- NA
str(traindata)
require(ggplot2)
require(caret)
require(randomForest)
data <- read.csv("pml-training.csv", stringsAsFactors=FALSE, na.strings=c("NA", "NULL"))
testdata <- read.csv("pml-testing.csv", stringsAsFactors=FALSE, na.strings=c("NA", "NULL"))
data$classe <- as.factor(data$classe)
class.histogram <- ggplot(data, aes(x=classe, fill = classe)) +
geom_histogram()+
labs(title = "Figure A: histogram of classe variable", x = "the class", y = "total nr of cases for that class")
class.histogram
indices <- grepl("_x$|_y$|_z$|^roll_|^pitch_|^yaw_|^total_accel_|classe", names(data))
data <- data[,indices]
indices_test <- grepl("_x$|_y$|_z$|^roll_|^pitch_|^yaw_|^total_accel_|problem_id", names(testdata))
testdata <- testdata[,indices_test]
inTrain <- createDataPartition(y=data$classe, p=0.6, list=FALSE)
training <- data[inTrain,]
validation <- data[-inTrain,]
set.seed(123)
model <- randomForest(x=training[,-53], y=training$classe, ntree=600, keep.forest=TRUE)
model
confusionMatrix(validation$classe, predict(model, validation))
answers <- as.character(predict(model, testdata))
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
library(ElemStatLearn);
data(vowel.train);
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
forest.model <- train(y~., method = "rf", data = vowel.train)
library(caret)
forest.model <- train(y~., method = "rf", data = vowel.train)
boosted.model <- train(y~., method = "gbm", data = vowel.train)
confusionMatrix(vowel.test$y, predict(forest.model, vowel.test))
confusionMatrix(vowel.test$y, predict(boosted.model, vowel.test))
confusionMatrix(predict(forest.model, vowel.test), predict(boosted.model, vowel.test))
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
str(training)
forest.model <- train(diagnosis~., method="rf", data=training)
boosted.model <- train(diagnosis~., method="gbm", data=training)
lineair.model <- train(diagnosis~., method="lda", data=training)
pred.f <- predict(forest.model, testing)
pred.b <- predict(boosted.model, testing)
pred.l <- predict(lineair.model, testing)
predDF <- data.frame(pred.f, pred.b, pred.l, diagnosis=testing$diagnosis)
combiModel <- train(diagnosis~., method="rf", data=predDF)
comboPred <- predict(combiModel, predDF)
forest.model$results$Accuracy
boosted.model$results$Accuracy
lineair.model$results$Accuracy
combiModel$results$Accuracy
confusionMatrix(testing$diagnosis, predict(forest.model, testing))
confusionMatrix(testing$diagnosis, predict(boosted.model, testing))
confusionMatrix(testing$diagnosis, predict(lineair.model, testing))
confusionMatrix(testing$diagnosis, predict(combiModel, testing))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
getModelInfo()
?train
names(getModelInfo())
str(training)
lasso.model <- train(CompressiveStrength~., method="lasso", data=training)
?plot.enet
class(lasso.model)
plot(lasso.model, xvar="penalty", use.color=TRUE)
lasso.model
?enet
enet(x=training[,-9], y=training$CompressiveStrength, trace=TRUE)
enet(x=as.matrix(training[,-9]), y=training$CompressiveStrength, trace=TRUE)
enetobject <- enet(x=as.matrix(training[,-9]), y=training$CompressiveStrength, trace=TRUE)
names(training)
library(lubridate)
install.packages(lubridate)
install.packages("lubridate")
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
library(forecast)
?bats
timeseriesmodel <- bats(y=tstrain)
?forecast
results <- forecast(timeseriesmodel, h=testing)
results <- forecast(timeseriesmodel, h=265)
results$model
results
str(tstrain)
str(testing)
rm(results)
?bats
tstest = ts(testing$visitsTumblr)
?forecast
timeseriesmodel(tstest)
t <- forecast(tstest, h=235, level=0.95)
t
summary(t)
plot(t)
plot(timeseriesmodel)
results <- forecast(bats(tstest), h=265, level=.95)
summary(results)
results$model
rm(t, results)
rm(tstest)
?bats
tsmodel <- bats(tstrain)
?forecast
tstest <- ts(testing$visitsTumblr)
fvalues <- forecast(tsmodel, h=tstest, level=.95)
fvalues <- forecast(tsmodel, h=length(tstest), level=.95)
fvalues
summary(fvalues)
rm(tsmodel, timeseriesmodel, fvalues)
model <- bats(tstrain)
summary(model)
results <- forecast(model, h=235, level=.95)
accuracy(results)
plot(results)
library(lubridate)
library(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
model <- bats(y=tstrain)
fcast <- forecast(model, h=235, level=.95)
tstest <- ts(testing$visitsTumblr)
accuracy(fcast, tstest)
str(dat)
testing2 <- dat[(year(dat$date)) > 2012,]
testing2 <- training-testing
accuracy(fcast, tstrain)
?accuracy
accuracy(f=fcast, x=training$visitsTumblr)
accuracy(f=fcast, x=testing)
accuracy(f=fcast, x=tstrain)
accuracy(f=fcast, x=tstest)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
model <- train(CompressiveStrength~., method="svm", data=training)
library(caret)
model <- train(CompressiveStrength~., method="svm", data=training)
names(getModelInfo())
?svm
model <- svm(CompressiveStrength~., data=training)
confusionMatrix(testing$CompressiveStrength, predict(model, testing))
preds <- predict(model, testing)
confusionMatrix(testing$CompressiveStrength, preds)
length(testing$CompressiveStrength)
length(preds)
confusionMatrix(testing$compressiveStrength, preds)
str(testing)
str(preds)
levels(preds)
str(training)
?svm
model <- svm(CompressiveStrength~., data=training, type=eps-regression)
model <- svm(CompressiveStrength~., data=training, type="eps-regression")
confusionMatrix(testing$CompressiveStrength, predict(model, testing))
model <- svm(x=training, y=training$CompressiveStrength, type="eps-regression")
confusionMatrix(testing$CompressiveStrength, predict(model, testing))
preds <- predict(model, testing)
model
sqrt( sum( (testing$CompressiveStrength - preds)^2 , na.rm = TRUE ) / nrow(testing) )
sqrt(sum(preds-mean(testing$CompressiveStrength))^2)
sqrt(mean(preds-testing$CompressiveStrength)^2)
rmse(preds, testing$CompressiveStrength, na.rm=TRUE)
install.packages("hydroGOF")
library(hydroGOF)
rmse(preds, testing$CompressiveStrength, na.rm=TRUE)
model <- svm(CompressiveStrength~., data=training, type="eps-regression"
model <- svm(CompressiveStrength~., data=training)
rm(preds)
preds <- predict(model, testing)
preds
sqrt((1/nrow(testing))* sum(preds-testing$CompressiveStrength)^2)
s.diff <- sum(preds-testings$CompressiveStrength)^2
s.diff <- sum(preds-testing$CompressiveStrength)^2
ns.diff <- s.diff/nrow(testing)
testing$CompressiveStrength
rm(ns.diff, s.diff)
difference.sum <- (preds-testings$CompressiveStrength)
difference.sum <- (preds-testing$CompressiveStrength)
difference.sum <- sum(preds-testing$CompressiveStrength)^2
mean.difference <- mean(difference.sum)
sqrt(mean.difference)
rm(difference.s, mean.difference)
rm(difference.sum)
errors <- preds-testing$CompressiveStrength
errors.squared <- errors^2
mean(errors.squared)
mean.errors.squared <- mean(errors.squared)
sqrt(mean.errors.squared)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
enetObject <- enet(x=as.matrix(training[,-9]), y=training$CompressiveStrength, trace=TRUE)
?enet
library(caret)
library(elasticnet)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
enetObject <- enet(x=as.matrix(training[,-9]), y=training$CompressiveStrength, trace=TRUE)
names(training)
?enet
enetObject <- enet(x=as.matrix(training[,-9]), y=training$CompressiveStrength, lambda=0, trace=TRUE)
plot(enetObject)
plot.enet(enetObject)
install.packages('manipulate')
install.packages("manipulate")
library(manipulate)
install.packages("devtools")
install.packages("rtools")
library(rtools)
install.packages("Rtools")
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages("shiny")
library(shiny)
shiny::runApp()
shiny::runApp()
shiny::runApp()
?lm
data(mtcars)
str(mtcars)
model <- lm(mpg ~ am + gear, mtcars)
test <- (0, 4)
test <- c(0, 4)
predict(model, test)
?predict
?mtcars
unique(mtcars$gear)
v1 <- mtcars$mpg
v2 <- predict(model, mtcars)
df <- as.data.frame(cbind(v1,v2))
df
shiny::runApp()
shiny::runApp()
?numericInput()
?radioButtons
shiny::runApp()
?numericInput
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?actioButton
?actionButton
shiny::runApp()
shiny::runApp()
?isolate
shiny::runApp()
shiny::runApp()
shiny::runApp()
data(mtcars)
str(mtcars)
mean(cyl)
mean(mtcars$cyl)
lower(mean(mtcars$cyl))
?round
floor(mean(mtcars$cyl))
floor(mean(mtcars$disp))
floor(mean(mtcars$hp))
floor(mean(mtcars$drat))
mean(mtcars$drat))
mean(mtcars$drat)
mean(mtcars$wt)
mean(mtcars$qsec)
mean(mtcars$vs)
lower(mean(mtcars$vs))
floor(mean(mtcars$vs))
floor(mean(mtcars$carb))
verbatimTextOutput
?verbatimTextOutput
?goButton
?submitButton
shiny::runApp()
shiny::runApp()
shiny::runApp()
?as.data.frame
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
?round
?p
?paste
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
library(markdown)
knit2html("HowDoesItWork.Rmd")
library(knitr)
knit2html("HowDoesItWork.Rmd")
?includeMarkdown
shiny::runApp()
library(devtools)
install.packages("Rtools")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='drststamper', token='1580F276FB105159C231A839C41FC54E', secret='KA/coKgU9rEMQVs/HC+xyZ3lishdfeTyH2FPZVy+')
shinyapps::deployApp('C:/Users/thierry/Documents/GitHub/DevelopingDataProduccts')
shinyapps::deployApp('C:/Users/thierry/Documents/GitHub/DevelopingDataProducts')
require(slidify)
require("slidify")
library(slidify)
library(devtools)
install.packages("Rtools")
install.packages("devtools")
install.packages("Rtools")
library(devtools)
find_rtools()
library(devtools)
install_github("slidify")
install_github("slidify", "manrathv")
install_github("slidify", "manrathv/slidify")
install_githbu('slidify', 'ramnathv')
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
setwd("~/GitHub/DevelopingDataProducts")
author("MPG_EstimatorApp")
data(mtcars)
model <- lm(mpg ~ am + gear, mtcars)
model$coef
library(knitr)
slidify("index.Rmd")
slidify('index.Rmd')
browseURL("index.html")
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
nrow(mtcars)
slidify('index.Rmd')
browseURL("index.html")
